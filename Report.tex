% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{tikz}
\usetikzlibrary{shapes.geometric,arrows}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Statistical Learning Project},
  pdfauthor={Marlon Helbing, Nemanja Ilic, Daniele Virzì},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Statistical Learning Project}
\author{Marlon Helbing, Nemanja Ilic, Daniele Virzì}
\date{2024-06-24}

\begin{document}
\maketitle

\hypertarget{introduction}{%
\section{1. Introduction}\label{introduction}}

This project is a collaborative effort of three \emph{Data Science}
students; \emph{Marlon Helbing}, \emph{Nemanja Ilic}, \emph{Daniele
Virzì}. It is an academic project that will be graded based on the
quality and depth of the analysis. The project aims to apply the
concepts and techniques from the \emph{Statistical Learning} course to a
real-world dataset. Our project is based on the \emph{HR Analytics Case
Study} and we will use the programming language \emph{R} to perform the
analysis. As previously stated, the scope of this project is to assess
the knowledge we have gained from the course. Because of this, in our
project work, we were only allowed to utilize the models and techniques
covered in the lectures; we were not permitted to use any
\texttt{Tidyverse} R-packages, like \texttt{ggplot} or \texttt{ggplot2}.

\hypertarget{dataset}{%
\subsection{1.1 Dataset}\label{dataset}}

\begin{itemize}
\item
  \href{https://www.kaggle.com/datasets/vjchoudhary7/hr-analytics-case-study}{\textbf{HR
  Analytics Case Study}}: This set of datasets, sourced from
  \emph{Kaggle}, contains information about employees working in a
  company. These data are collected to understand why the employees are
  leaving the company and to predict the employees who are likely to
  leave the company. There are several datasets available for this case
  study but for our purposes we have chosen and merged just two of them,
  \texttt{general\_data} and \texttt{employee\_survey\_data}. The final
  dataset contains 4410 observations and 27 variables. The variables are
  as follows:

  \begin{itemize}
  \tightlist
  \item
    \textbf{\texttt{Age}}: Age of the employee.
  \item
    \textbf{\texttt{Attrition}}: Whether the employee has left the
    company or not.
  \item
    \textbf{\texttt{BusinessTravel}}: Frequency of travel for the
    employee.
  \item
    \textbf{\texttt{Department}}: Department of the employee.
  \item
    \textbf{\texttt{DistanceFromHome}}: Distance of the employee's
    residence from the company.
  \item
    \textbf{\texttt{Education}}: Education level of the employee.
  \item
    \textbf{\texttt{EducationField}}: Field of education of the
    employee.
  \item
    \textbf{\texttt{EmployeeCount}}: Employee count.
  \item
    \textbf{\texttt{EmployeeID}}: Employee ID.
  \item
    \textbf{\texttt{Gender}}: The gender of the employee.
  \item
    \textbf{\texttt{JobLevel}}: Job level of the employee.
  \item
    \textbf{\texttt{JobRole}}: Job role of the employee.
  \item
    \textbf{\texttt{MaritalStatus}}: Marital status of the employee.
  \item
    \textbf{\texttt{MonthlyIncome}}: Monthly income of the employee.
  \item
    \textbf{\texttt{NumCompaniesWorked}}: Number of companies the
    employee has worked for.
  \item
    \textbf{\texttt{Over18}}: Whether the employee is over 18 years old
    or not.
  \item
    \textbf{\texttt{PercentSalaryHike}}: Percentage increase in salary.
  \item
    \textbf{\texttt{StandardHours}}: Standard hours of work.
  \item
    \textbf{\texttt{StockOptionLevel}}: Stock option level of the
    employee.
  \item
    \textbf{\texttt{TotalWorkingYears}}: Total years the employee has
    worked.
  \item
    \textbf{\texttt{TrainingTimesLastYear}}: Number of times the
    employee was trained last year.
  \item
    \textbf{\texttt{YearsAtCompany}}: Number of years the employee has
    worked at the company.
  \item
    \textbf{\texttt{YearsSinceLastPromotion}}: Number of years since the
    last promotion.
  \item
    \textbf{\texttt{YearsWithCurrManager}}: Number of years the employee
    has worked with the current manager.
  \item
    \textbf{\texttt{EnvironmentSatisfaction}}: Environment satisfaction
    level of the employee.
  \item
    \textbf{\texttt{JobSatisfaction}}: Job satisfaction level of the
    employee.
  \item
    \textbf{\texttt{WorkLifeBalance}}: Work-life balance level of the
    employee.
  \end{itemize}
\end{itemize}

\hypertarget{project-goals}{%
\subsection{1.2 Project goals}\label{project-goals}}

The main objectives of this project are:

\begin{itemize}
\item
  \textbf{Regression Model}: To predict \texttt{YearsAtCompany} based on
  the available features, in order to understand the factors that
  influence the number of years an employee stays in the company. In
  this way, the company can take actions to retain employees for a
  longer period of time.
\item
  \textbf{Classification Model}: To predict \texttt{Attrition} based on
  the available features, in order to understand the factors that
  influence the attrition of employees in the company. In this way, the
  company can take actions to reduce the attrition rate.
\end{itemize}

\hypertarget{methodology}{%
\subsection{1.3 Methodology}\label{methodology}}

\begin{center}\includegraphics{Report_files/figure-latex/unnamed-chunk-1-1} \end{center}

\hypertarget{data-loading}{%
\section{2. Data Loading}\label{data-loading}}

We start by loading the necessary libraries and the data into the R
environment. The libraries that we will be using in this project are:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(MASS) }\CommentTok{\# For step, glm, lda, qda}
\FunctionTok{library}\NormalTok{(e1071) }\CommentTok{\# For naiveBayes}
\FunctionTok{library}\NormalTok{(car) }\CommentTok{\# For vif}
\FunctionTok{library}\NormalTok{(corrplot) }\CommentTok{\# For plotting correlation matrix}
\FunctionTok{library}\NormalTok{(pROC) }\CommentTok{\# For ROC curve}
\end{Highlighting}
\end{Shaded}

The data is loaded from the \texttt{general\_data.csv} and
\texttt{employee\_survey\_data.csv} files. We then merge the two
datasets based on the \texttt{EmployeeID} variable.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{general\_data }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"./data/general\_data.csv"}\NormalTok{)}
\NormalTok{employee\_survey\_data }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"./data/employee\_survey\_data.csv"}\NormalTok{)}
\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{merge}\NormalTok{(general\_data, employee\_survey\_data, }\AttributeTok{by =} \StringTok{"EmployeeID"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{data-cleaning}{%
\section{3. Data Cleaning}\label{data-cleaning}}

\hypertarget{handling-missing-values}{%
\subsection{3.1 Handling missing values}\label{handling-missing-values}}

We check for missing values in the dataset and find that there are 111
misssing values.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{missing\_values }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(data))}
\NormalTok{missing\_values}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 111
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{na.omit}\NormalTok{(data)}
\end{Highlighting}
\end{Shaded}

\hypertarget{handling-duplicate-rows}{%
\subsection{3.2 Handling duplicate rows}\label{handling-duplicate-rows}}

We check for duplicate rows in the dataset and find that there are no
duplicate rows.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{duplicates }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(}\FunctionTok{duplicated}\NormalTok{(data))}
\NormalTok{duplicates}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\hypertarget{removing-unnecessary-columns}{%
\subsection{3.3 Removing unnecessary
columns}\label{removing-unnecessary-columns}}

We remove the \texttt{EmployeeID}, because it is a unique identifier and
does not provide any useful information for the analysis. We also remove
the \texttt{Over18}, \texttt{StandardHours}, and \texttt{EmployeeCount}
columns because they have the same value for all employees and so the
variance is zero.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data }\OtherTok{\textless{}{-}}\NormalTok{ data[, }\SpecialCharTok{!}\NormalTok{(}\FunctionTok{names}\NormalTok{(data) }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"EmployeeID"}\NormalTok{, }\StringTok{"Over18"}\NormalTok{, }\StringTok{"StandardHours"}\NormalTok{, }\StringTok{"EmployeeCount"}\NormalTok{))]}
\end{Highlighting}
\end{Shaded}

\hypertarget{data-preprocessing}{%
\section{4. Data Preprocessing}\label{data-preprocessing}}

\hypertarget{encoding-categorical-variables}{%
\subsection{4.1 Encoding categorical
variables}\label{encoding-categorical-variables}}

We encode the categorical variables as factors in order to use them in
the regression and classification models.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data}\SpecialCharTok{$}\NormalTok{Attrition }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{Attrition)}
\NormalTok{data}\SpecialCharTok{$}\NormalTok{Gender }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{Gender)}
\NormalTok{data}\SpecialCharTok{$}\NormalTok{BusinessTravel }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{BusinessTravel)}
\NormalTok{data}\SpecialCharTok{$}\NormalTok{JobRole }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{JobRole)}
\NormalTok{data}\SpecialCharTok{$}\NormalTok{Department }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{Department)}
\NormalTok{data}\SpecialCharTok{$}\NormalTok{EducationField }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{EducationField)}
\NormalTok{data}\SpecialCharTok{$}\NormalTok{MaritalStatus }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{MaritalStatus)}
\NormalTok{data}\SpecialCharTok{$}\NormalTok{StockOptionLevel }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{StockOptionLevel)}
\NormalTok{data}\SpecialCharTok{$}\NormalTok{Education }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{Education)}
\NormalTok{data}\SpecialCharTok{$}\NormalTok{JobLevel }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{JobLevel)}
\NormalTok{data}\SpecialCharTok{$}\NormalTok{EnvironmentSatisfaction }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{EnvironmentSatisfaction)}
\NormalTok{data}\SpecialCharTok{$}\NormalTok{JobSatisfaction }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{JobSatisfaction)}
\NormalTok{data}\SpecialCharTok{$}\NormalTok{WorkLifeBalance }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{WorkLifeBalance)}
\end{Highlighting}
\end{Shaded}

\hypertarget{log-transformation}{%
\subsection{4.2 Log transformation}\label{log-transformation}}

We perform log transformation on the \texttt{MonthlyIncome} variable to
make it more normally distributed.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data}\SpecialCharTok{$}\NormalTok{MonthlyIncome }\OtherTok{\textless{}{-}} \FunctionTok{log}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{MonthlyIncome)}
\end{Highlighting}
\end{Shaded}

\hypertarget{check-the-structure-of-the-dataset}{%
\subsection{4.3 Check the structure of the
dataset}\label{check-the-structure-of-the-dataset}}

We check the structure of the dataset to ensure that the data
preprocessing steps have been applied correctly.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    4300 obs. of  23 variables:
##  $ Age                    : int  51 31 32 38 32 46 28 29 31 25 ...
##  $ Attrition              : Factor w/ 2 levels "No","Yes": 1 2 1 1 1 1 2 1 1 1 ...
##  $ BusinessTravel         : Factor w/ 3 levels "Non-Travel","Travel_Frequently",..: 3 2 2 1 3 3 3 3 3 1 ...
##  $ Department             : Factor w/ 3 levels "Human Resources",..: 3 2 2 2 2 2 2 2 2 2 ...
##  $ DistanceFromHome       : int  6 10 17 2 10 8 11 18 1 7 ...
##  $ Education              : Factor w/ 5 levels "1","2","3","4",..: 2 1 4 5 1 3 2 3 3 4 ...
##  $ EducationField         : Factor w/ 6 levels "Human Resources",..: 2 2 5 2 4 2 4 2 2 4 ...
##  $ Gender                 : Factor w/ 2 levels "Female","Male": 1 1 2 2 2 1 2 2 2 1 ...
##  $ JobLevel               : Factor w/ 5 levels "1","2","3","4",..: 1 1 4 3 1 4 2 2 3 4 ...
##  $ JobRole                : Factor w/ 9 levels "Healthcare Representative",..: 1 7 8 2 8 6 8 8 3 3 ...
##  $ MaritalStatus          : Factor w/ 3 levels "Divorced","Married",..: 2 3 2 2 3 2 3 2 2 1 ...
##  $ MonthlyIncome          : num  11.8 10.6 12.2 11.3 10.1 ...
##  $ NumCompaniesWorked     : int  1 0 1 3 4 3 2 2 0 1 ...
##  $ PercentSalaryHike      : int  11 23 15 11 12 13 20 22 21 13 ...
##  $ StockOptionLevel       : Factor w/ 4 levels "0","1","2","3": 1 2 4 4 3 1 2 4 1 2 ...
##  $ TotalWorkingYears      : int  1 6 5 13 9 28 5 10 10 6 ...
##  $ TrainingTimesLastYear  : int  6 3 2 5 2 5 2 2 2 2 ...
##  $ YearsAtCompany         : int  1 5 5 8 6 7 0 0 9 6 ...
##  $ YearsSinceLastPromotion: int  0 1 0 7 0 7 0 0 7 1 ...
##  $ YearsWithCurrManager   : int  0 4 3 5 4 7 0 0 8 5 ...
##  $ EnvironmentSatisfaction: Factor w/ 4 levels "1","2","3","4": 3 3 2 4 4 3 1 1 2 2 ...
##  $ JobSatisfaction        : Factor w/ 4 levels "1","2","3","4": 4 2 2 4 1 2 3 2 4 1 ...
##  $ WorkLifeBalance        : Factor w/ 4 levels "1","2","3","4": 2 4 1 3 3 2 1 3 3 3 ...
\end{verbatim}

\hypertarget{exploratory-data-analysis}{%
\section{5. Exploratory Data Analysis}\label{exploratory-data-analysis}}

\hypertarget{categorical-variables}{%
\subsection{5.1 Categorical variables}\label{categorical-variables}}

We plot the distribution of the categorical variables in the dataset.

\begin{center}\includegraphics{Report_files/figure-latex/categorical_variables1-1} \end{center}

\begin{center}\includegraphics{Report_files/figure-latex/categorical_variables2-1} \end{center}

\begin{center}\includegraphics{Report_files/figure-latex/categorical_variables3-1} \end{center}

\newpage

We notice that \texttt{JobSatisfaction} and
\texttt{EnvironmentSatisfaction} are extremely similar. To check this we
compute the chi squared statistic between these two. The null hypothesis
is that the two variables are independent. The p-value is less than 0.1,
so we reject the null hypothesis and conclude that the two variables are
dependent. So we remove the \texttt{EnvironmentSatisfaction} variable
from the dataset.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{contingency\_table }\OtherTok{\textless{}{-}} \FunctionTok{table}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{EnvironmentSatisfaction, data}\SpecialCharTok{$}\NormalTok{JobSatisfaction)}
\NormalTok{chi\_squared }\OtherTok{\textless{}{-}} \FunctionTok{chisq.test}\NormalTok{(contingency\_table) }
\NormalTok{chi\_squared}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Pearson's Chi-squared test
## 
## data:  contingency_table
## X-squared = 15.327, df = 9, p-value = 0.08235
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data}\SpecialCharTok{$}\NormalTok{EnvironmentSatisfaction }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
\end{Highlighting}
\end{Shaded}

\hypertarget{numerical-variables}{%
\subsection{5.2 Numerical variables}\label{numerical-variables}}

We plot the distribution of the numerical variables in the dataset.

\begin{center}\includegraphics{Report_files/figure-latex/numerical_variables-1} \end{center}

\hypertarget{years-at-company-analysis}{%
\subsection{5.3 Years At Company
Analysis}\label{years-at-company-analysis}}

We plot the distribution of the \texttt{YearsAtCompany} variable, our
target variable for the regression model.

\begin{center}\includegraphics{Report_files/figure-latex/years_at_company-1} \end{center}

Then we plot the boxplot of the \texttt{YearsAtCompany} variable against
all the categorical variables in the dataset.

\begin{center}\includegraphics{Report_files/figure-latex/years_at_company_boxplot-1} \end{center}

\hypertarget{attrition-analysis}{%
\subsection{5.4 Attrition Analysis}\label{attrition-analysis}}

We plot the distribution of the \texttt{Attrition} variable, our target
variable for the classification model.

\begin{center}\includegraphics{Report_files/figure-latex/attrition-1} \end{center}

Then we plot the boxplot of the \texttt{Attrition} variable against all
the numerical variables in the dataset.

\begin{center}\includegraphics{Report_files/figure-latex/attrition_boxplot-1} \end{center}

\hypertarget{correlation-analysis}{%
\subsection{5.5 Correlation Analysis}\label{correlation-analysis}}

We calculate the correlation matrix of the numerical variables in the
dataset.

\begin{center}\includegraphics{Report_files/figure-latex/correlation_matrix-1} \end{center}

We notice that \texttt{YearsAtCompany} is highly correlated with
\texttt{YearsWithCurrManager}. We will start from this variable to build
the regression model.

\newpage

\hypertarget{model-building}{%
\section{6. Model Building}\label{model-building}}

We first split the dataset into a training set and a test set. We use
80\% of the data for training and 20\% for testing.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{dim}\NormalTok{(data)[}\DecValTok{1}\NormalTok{]}
\NormalTok{test }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{n, n}\SpecialCharTok{*}\FloatTok{0.2}\NormalTok{) }\CommentTok{\# indexes of data in the test set}
\NormalTok{train }\OtherTok{\textless{}{-}} \FunctionTok{setdiff}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{n, test) }\CommentTok{\# indexes of data in training set}
\NormalTok{test.data }\OtherTok{\textless{}{-}}\NormalTok{ data[test, ] }\CommentTok{\# validation set}
\NormalTok{train.data }\OtherTok{\textless{}{-}}\NormalTok{ data[train, ] }\CommentTok{\# training set}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Number of observations in the training set:  3440"
\end{verbatim}

\begin{verbatim}
## [1] "Number of observations in the test set:  860"
\end{verbatim}

\hypertarget{regression-model}{%
\subsection{6.1 Regression Model}\label{regression-model}}

The goal of this analysis is to predict the number of years an employee
has worked at the company. For this purpose, we will build a regression
model and, to evaluate the performance of the model, we will use the
R-squared metric. The main idea is to start with a simple model and then
add more variables to improve the model. The best model will be the one
with the highest R-squared value and the variables with the highest
significance.

\hypertarget{simple-linear-regression}{%
\subsubsection{6.1.1 Simple Linear
Regression}\label{simple-linear-regression}}

We start building a simple regression model to predict the
\texttt{YearsAtCompany} variable. We use the
\texttt{YearsWithCurrManager} variable as the predictor.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_slr }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(YearsAtCompany }\SpecialCharTok{\textasciitilde{}}\NormalTok{ YearsWithCurrManager, }\AttributeTok{data =}\NormalTok{ train.data)}
\FunctionTok{summary}\NormalTok{(model\_slr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = YearsAtCompany ~ YearsWithCurrManager, data = train.data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.0139 -2.1219 -0.8546  0.4487 31.4487 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(>|t|)    
## (Intercept)            1.5513     0.1021   15.19   <2e-16 ***
## YearsWithCurrManager   1.3213     0.0189   69.91   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 3.909 on 3438 degrees of freedom
## Multiple R-squared:  0.5871, Adjusted R-squared:  0.5869 
## F-statistic:  4887 on 1 and 3438 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{center}\includegraphics{Report_files/figure-latex/plot_simple_regression_model_residuals-1} \end{center}

Since we use only one variable to build the model, we can plot the
regression line on the scatter plot to visualize how well the model fits
the data.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(train.data}\SpecialCharTok{$}\NormalTok{YearsWithCurrManager, train.data}\SpecialCharTok{$}\NormalTok{YearsAtCompany, }
     \AttributeTok{xlab =} \StringTok{"YearsWithCurrManager"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"YearsAtCompany"}\NormalTok{,}
     \AttributeTok{main =} \StringTok{"Simple Linear Regression"}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(model\_slr, }\AttributeTok{col =} \StringTok{"red"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{Report_files/figure-latex/plot_simple_regression_model-1} \end{center}

From the R-squared value and the plots, we can see that the model is too
simple and does not fit the data well.

\hypertarget{multiple-linear-regression}{%
\subsubsection{6.1.2 Multiple Linear
Regression}\label{multiple-linear-regression}}

The first model has an R-squared value of 0.58, which is not very high.
We try to improve the model by adding more variables. We use all the
numerical variables in the dataset as predictors.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_mlr1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(YearsAtCompany }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train.data)}
\NormalTok{R2\_mlr1 }\OtherTok{\textless{}{-}} \FunctionTok{summary}\NormalTok{(model\_mlr1)}\SpecialCharTok{$}\NormalTok{r.squared}
\NormalTok{R2\_mlr1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.7528953
\end{verbatim}

\hypertarget{multiple-linear-regression-with-feature-selection}{%
\subsubsection{6.1.3 Multiple Linear Regression with Feature
Selection}\label{multiple-linear-regression-with-feature-selection}}

The multiple regression model has an R-squared value of 0.75, which is
better than the simple regression model. However, we can improve the
model by checking for multicollinearity in the multiple regression model
and remove the variables that are highly correlated (VIF \textgreater{}
5). Then, we build a new model with the remaining variables.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vif\_values }\OtherTok{\textless{}{-}} \FunctionTok{vif}\NormalTok{(model\_mlr1)}
\NormalTok{vif\_values }\SpecialCharTok{\textgreater{}} \DecValTok{5}
\NormalTok{columns\_to\_remove }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Department"}\NormalTok{, }\StringTok{"EducationField"}\NormalTok{)}
\NormalTok{data\_reduced }\OtherTok{\textless{}{-}}\NormalTok{ train.data[, }\SpecialCharTok{!}\FunctionTok{names}\NormalTok{(data) }\SpecialCharTok{\%in\%}\NormalTok{ columns\_to\_remove]}
\NormalTok{data\_reduced\_test }\OtherTok{\textless{}{-}}\NormalTok{ test.data[, }\SpecialCharTok{!}\FunctionTok{names}\NormalTok{(data) }\SpecialCharTok{\%in\%}\NormalTok{ columns\_to\_remove]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_mlr2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(YearsAtCompany }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ data\_reduced)}
\NormalTok{R2\_mlr2 }\OtherTok{\textless{}{-}} \FunctionTok{summary}\NormalTok{(model\_mlr2)}\SpecialCharTok{$}\NormalTok{r.squared}
\NormalTok{R2\_mlr2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.7515676
\end{verbatim}

The R-squared value of the new model is 0.75, which is the same as the
previous model. We can conclude that the variables \texttt{Department}
and \texttt{EducationField} do not contribute to the model.

\hypertarget{polynomial-regression}{%
\subsubsection{6.1.4 Polynomial
Regression}\label{polynomial-regression}}

We can try to improve the model by adding polynomial terms to the model.
In order to do this, we will add the square of all the numerical
variables in the dataset as predictors.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_pr }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(YearsAtCompany }\SpecialCharTok{\textasciitilde{}} 
               \FunctionTok{poly}\NormalTok{(Age, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+} 
               \FunctionTok{poly}\NormalTok{(Attrition, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+} 
               \FunctionTok{poly}\NormalTok{(BusinessTravel, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+} 
               \FunctionTok{poly}\NormalTok{(DistanceFromHome, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+} 
               \FunctionTok{poly}\NormalTok{(Education, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+} 
               \FunctionTok{poly}\NormalTok{(Gender, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+} 
               \FunctionTok{poly}\NormalTok{(JobLevel, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+} 
               \FunctionTok{poly}\NormalTok{(JobRole, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+} 
               \FunctionTok{poly}\NormalTok{(MaritalStatus, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+} 
               \FunctionTok{poly}\NormalTok{(MonthlyIncome, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+} 
               \FunctionTok{poly}\NormalTok{(NumCompaniesWorked, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+} 
               \FunctionTok{poly}\NormalTok{(PercentSalaryHike, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+} 
               \FunctionTok{poly}\NormalTok{(StockOptionLevel, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+} 
               \FunctionTok{poly}\NormalTok{(TotalWorkingYears, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+} 
               \FunctionTok{poly}\NormalTok{(TrainingTimesLastYear, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+} 
               \FunctionTok{poly}\NormalTok{(YearsSinceLastPromotion, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+}
               \FunctionTok{poly}\NormalTok{(YearsWithCurrManager, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+} 
               \FunctionTok{poly}\NormalTok{(JobSatisfaction, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+}
               \FunctionTok{poly}\NormalTok{(WorkLifeBalance, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{),}
               \AttributeTok{data =}\NormalTok{ data\_reduced)}
\NormalTok{R2\_pr }\OtherTok{\textless{}{-}} \FunctionTok{summary}\NormalTok{(model\_pr)}\SpecialCharTok{$}\NormalTok{r.squared}
\NormalTok{R2\_pr}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.7763953
\end{verbatim}

The R-squared value of the polynomial regression model is 0.77, which is
not significantly better than the multiple regression model.

\hypertarget{polynomial-regression-with-feature-selection}{%
\subsubsection{6.1.5 Polynomial Regression with Feature
Selection}\label{polynomial-regression-with-feature-selection}}

We can try to improve the polynomial regression model by removing the
variables that are not significant. We use the backward selection method
to remove the variables that do not contribute to the model minimizing
the AIC value.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{backward\_model }\OtherTok{\textless{}{-}} \FunctionTok{step}\NormalTok{(model\_pr, }\AttributeTok{direction =} \StringTok{"backward"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{R2\_backward }\OtherTok{\textless{}{-}} \FunctionTok{summary}\NormalTok{(backward\_model)}\SpecialCharTok{$}\NormalTok{r.squared}
\NormalTok{R2\_backward}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.7750299
\end{verbatim}

After the backward elimination, the R-squared value of the model is
0.77, which is the same as the previous model. We can conclude that the
backward elimination did not improve the model at all. So, we try to
improve the selecting manually the variables that are significant.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{best\_model }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(YearsAtCompany }
                  \SpecialCharTok{\textasciitilde{}} \FunctionTok{poly}\NormalTok{(Age, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+}
                    \FunctionTok{poly}\NormalTok{(Education, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+}
\NormalTok{                    Gender }\SpecialCharTok{+}
                    \FunctionTok{poly}\NormalTok{(NumCompaniesWorked , }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+}
\NormalTok{                    TotalWorkingYears }\SpecialCharTok{+}
                    \FunctionTok{poly}\NormalTok{(TrainingTimesLastYear, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+}
                    \FunctionTok{poly}\NormalTok{(YearsSinceLastPromotion, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+}
\NormalTok{                    YearsWithCurrManager }\SpecialCharTok{+}
                    \FunctionTok{poly}\NormalTok{(JobSatisfaction, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{),}
                  
                  \AttributeTok{data =}\NormalTok{ data\_reduced)}
\NormalTok{R2\_best }\OtherTok{\textless{}{-}} \FunctionTok{summary}\NormalTok{(best\_model)}\SpecialCharTok{$}\NormalTok{r.squared}
\NormalTok{R2\_best}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.7724469
\end{verbatim}

\hypertarget{final-model}{%
\subsubsection{6.1.6 Final Model}\label{final-model}}

We try to improve the model removing influential points by using the
Cook's distance method and setting a threshold of 3 times the mean
Cook's distance. First, we calculate the Cook's distance for each
observation and then we identify the influential points.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cooksd }\OtherTok{\textless{}{-}} \FunctionTok{cooks.distance}\NormalTok{(best\_model)}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(cooksd, }\AttributeTok{pch =} \StringTok{"*"}\NormalTok{, }\AttributeTok{cex =} \DecValTok{2}\NormalTok{, }\AttributeTok{main =} \StringTok{"Cook\textquotesingle{}s Distance"}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =} \DecValTok{3} \SpecialCharTok{*}\FunctionTok{mean}\NormalTok{(cooksd, }\AttributeTok{na.rm=}\ConstantTok{TRUE}\NormalTok{),  }\AttributeTok{col=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{), }\AttributeTok{lwd=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{Report_files/figure-latex/cooks_distance-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{influential }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(cooksd }\SpecialCharTok{\textgreater{}} \DecValTok{3}\SpecialCharTok{*}\FunctionTok{mean}\NormalTok{(cooksd, }\AttributeTok{na.rm=}\ConstantTok{TRUE}\NormalTok{))}
\FunctionTok{length}\NormalTok{(influential)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 226
\end{verbatim}

We can compare the boxplots of the original data and the influential
points to see if these points are outliers.

\begin{center}\includegraphics{Report_files/figure-latex/plot_influential_points-1} \end{center}

We can see that the influential points are mostly outliers so removing
these points can improve the model. We remove the influential points and
fit the final model.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{final\_train.data }\OtherTok{\textless{}{-}}\NormalTok{ data\_reduced[}\SpecialCharTok{{-}}\NormalTok{influential, ]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{final\_model }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(YearsAtCompany }
                  \SpecialCharTok{\textasciitilde{}} \FunctionTok{poly}\NormalTok{(Age, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+}
                    \FunctionTok{poly}\NormalTok{(Education, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+}
\NormalTok{                    Gender }\SpecialCharTok{+}
                    \FunctionTok{poly}\NormalTok{(NumCompaniesWorked , }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+}
\NormalTok{                    TotalWorkingYears }\SpecialCharTok{+}
                    \FunctionTok{poly}\NormalTok{(TrainingTimesLastYear, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+}
                    \FunctionTok{poly}\NormalTok{(YearsSinceLastPromotion, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+}
\NormalTok{                    YearsWithCurrManager }\SpecialCharTok{+}
                    \FunctionTok{poly}\NormalTok{(JobSatisfaction, }\DecValTok{2}\NormalTok{, }\AttributeTok{raw =} \ConstantTok{TRUE}\NormalTok{),}
                  
                  \AttributeTok{data =}\NormalTok{ final\_train.data)}
\NormalTok{R2\_final }\OtherTok{\textless{}{-}} \FunctionTok{summary}\NormalTok{(final\_model)}\SpecialCharTok{$}\NormalTok{r.squared}
\NormalTok{R2\_final}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.8417186
\end{verbatim}

\begin{center}\includegraphics{Report_files/figure-latex/plot_final_model-1} \end{center}

The R-squared value of the final model is 0.84 which is better than the
previous models. We can conclude that the outliers were affecting the
model. We can use this model to predict the years at the company for new
employees.

\hypertarget{classification-model}{%
\subsection{6.2 Classification Model}\label{classification-model}}

The second goal of this analysis is to predict the attrition of
employees. For this purpose, we will build a classification model and,
to evaluate the performance of the model, we will use the R-squared
metric. In this case, we can use defiance instead of RSS. This, because
we can treat the deviance in almost the same way as the residual sum of
squares in linear models, as a measure of the goodness of fit of the
model. Since the target variable is binary, we will use the logistic
regression model. The main idea is to start with all the variables and
then remove the variables that are not significant. The best model will
be the one with the highest R-squared value and the variables with the
highest significance.

\hypertarget{logistic-regression}{%
\subsubsection{6.2.1 Logistic Regression}\label{logistic-regression}}

We start by fitting the logistic regression model using all the
variables.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{initial\_model\_logit }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(Attrition }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train.data, }\AttributeTok{family =}\NormalTok{ binomial)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{summary\_model\_logit }\OtherTok{\textless{}{-}} \FunctionTok{summary}\NormalTok{(initial\_model\_logit)}
\NormalTok{R2\_logit }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ (summary\_model\_logit}\SpecialCharTok{$}\NormalTok{deviance }\SpecialCharTok{/}
\NormalTok{                 summary\_model\_logit}\SpecialCharTok{$}\NormalTok{null.deviance)}
\NormalTok{R2\_logit}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1820078
\end{verbatim}

\hypertarget{logistic-regression-with-feature-selection}{%
\subsubsection{6.2.2 Logistic Regression with Feature
Selection}\label{logistic-regression-with-feature-selection}}

The R-squared value of the model is 0.18 which is not very high. We can
use the stepwise selection method to select the best model. We start
with the full model and then we remove the variables that are not
significant.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{backward\_model\_logit }\OtherTok{\textless{}{-}} \FunctionTok{step}\NormalTok{(initial\_model\_logit, }\AttributeTok{direction =} \StringTok{"backward"}\NormalTok{)}
\NormalTok{summary\_backward\_model\_logit }\OtherTok{\textless{}{-}} \FunctionTok{summary}\NormalTok{(backward\_model\_logit)}
\NormalTok{summary\_backward\_model\_logit}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{R2\_backward\_logit }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ (summary\_backward\_model\_logit}\SpecialCharTok{$}\NormalTok{deviance }\SpecialCharTok{/}
\NormalTok{                          summary\_backward\_model\_logit}\SpecialCharTok{$}\NormalTok{null.deviance)}
\NormalTok{R2\_backward\_logit}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1760728
\end{verbatim}

Stepwise selection removed some variables that were not significant. The
R-squared value of the model is 0.17 which is worst. We can try to
improve the model by selecting the variables with the highest
significance.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{final\_model\_logit }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(Attrition }\SpecialCharTok{\textasciitilde{}} 
\NormalTok{                          Age }\SpecialCharTok{+} 
\NormalTok{                          BusinessTravel }\SpecialCharTok{+} 
\NormalTok{                          Department }\SpecialCharTok{+} 
\NormalTok{                          MaritalStatus }\SpecialCharTok{+} 
\NormalTok{                          NumCompaniesWorked }\SpecialCharTok{+} 
\NormalTok{                          TotalWorkingYears }\SpecialCharTok{+}
\NormalTok{                          TrainingTimesLastYear }\SpecialCharTok{+} 
\NormalTok{                          YearsSinceLastPromotion }\SpecialCharTok{+}
\NormalTok{                          YearsWithCurrManager }\SpecialCharTok{+}
\NormalTok{                          JobSatisfaction }\SpecialCharTok{+}
\NormalTok{                          WorkLifeBalance, }
                        \AttributeTok{data =}\NormalTok{ train.data, }\AttributeTok{family =}\NormalTok{ binomial)}

\NormalTok{summary\_best\_model\_logit }\OtherTok{\textless{}{-}} \FunctionTok{summary}\NormalTok{(final\_model\_logit)}
\NormalTok{R2\_best\_logit }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ (summary\_best\_model\_logit}\SpecialCharTok{$}\NormalTok{deviance }\SpecialCharTok{/} 
\NormalTok{                      summary\_best\_model\_logit}\SpecialCharTok{$}\NormalTok{null.deviance)}
\NormalTok{R2\_best\_logit}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1627382
\end{verbatim}

The R-squared value of this model is 0.16 which is the worst but has
only the significant variables. We can conclude that the logistic
regression model may not be the best model for this dataset. We can try
other classification models like LDA, QDA and Naive Bayes.

\newpage

\hypertarget{lda-linear-discriminant-analysis}{%
\subsubsection{6.2.3 LDA (Linear Discriminant
Analysis)}\label{lda-linear-discriminant-analysis}}

We fit the LDA model using the significant variables.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_lda }\OtherTok{\textless{}{-}} \FunctionTok{lda}\NormalTok{(Attrition }\SpecialCharTok{\textasciitilde{}} 
\NormalTok{                   Age }\SpecialCharTok{+} 
\NormalTok{                   BusinessTravel }\SpecialCharTok{+} 
\NormalTok{                   Department }\SpecialCharTok{+} 
\NormalTok{                   MaritalStatus }\SpecialCharTok{+} 
\NormalTok{                   NumCompaniesWorked }\SpecialCharTok{+} 
\NormalTok{                   TotalWorkingYears }\SpecialCharTok{+}
\NormalTok{                   TrainingTimesLastYear }\SpecialCharTok{+} 
\NormalTok{                   YearsSinceLastPromotion }\SpecialCharTok{+}
\NormalTok{                   YearsWithCurrManager }\SpecialCharTok{+}
\NormalTok{                   JobSatisfaction }\SpecialCharTok{+}
\NormalTok{                   WorkLifeBalance, }
                 \AttributeTok{data =}\NormalTok{ train.data)}
\NormalTok{model\_lda}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(model\_lda, }\AttributeTok{type=}\StringTok{"both"}\NormalTok{, }\AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{Report_files/figure-latex/lda_summary-1} \end{center}

\hypertarget{qda-quadratic-discriminant-analysis}{%
\subsubsection{6.2.4 QDA (Quadratic Discriminant
Analysis)}\label{qda-quadratic-discriminant-analysis}}

We fit the QDA model using the significant variables.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_qda }\OtherTok{\textless{}{-}} \FunctionTok{qda}\NormalTok{(Attrition }\SpecialCharTok{\textasciitilde{}} 
\NormalTok{                   Age }\SpecialCharTok{+} 
\NormalTok{                   BusinessTravel }\SpecialCharTok{+} 
\NormalTok{                   Department }\SpecialCharTok{+} 
\NormalTok{                   MaritalStatus }\SpecialCharTok{+} 
\NormalTok{                   NumCompaniesWorked }\SpecialCharTok{+} 
\NormalTok{                   TotalWorkingYears }\SpecialCharTok{+}
\NormalTok{                   TrainingTimesLastYear }\SpecialCharTok{+} 
\NormalTok{                   YearsSinceLastPromotion }\SpecialCharTok{+}
\NormalTok{                   YearsWithCurrManager }\SpecialCharTok{+}
\NormalTok{                   JobSatisfaction }\SpecialCharTok{+}
\NormalTok{                   WorkLifeBalance, }
                 \AttributeTok{data =}\NormalTok{ train.data)}
\NormalTok{model\_qda}
\end{Highlighting}
\end{Shaded}

\hypertarget{naive-bayes}{%
\subsubsection{6.2.5 Naive Bayes}\label{naive-bayes}}

We fit the Naive Bayes model using the significant variables.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_nb }\OtherTok{\textless{}{-}} \FunctionTok{naiveBayes}\NormalTok{(Attrition }\SpecialCharTok{\textasciitilde{}} 
\NormalTok{                         Age }\SpecialCharTok{+} 
\NormalTok{                         BusinessTravel }\SpecialCharTok{+} 
\NormalTok{                         Department }\SpecialCharTok{+} 
\NormalTok{                         MaritalStatus }\SpecialCharTok{+} 
\NormalTok{                         NumCompaniesWorked }\SpecialCharTok{+} 
\NormalTok{                         TotalWorkingYears }\SpecialCharTok{+}
\NormalTok{                         TrainingTimesLastYear }\SpecialCharTok{+} 
\NormalTok{                         YearsSinceLastPromotion }\SpecialCharTok{+}
\NormalTok{                         YearsWithCurrManager }\SpecialCharTok{+}
\NormalTok{                         JobSatisfaction }\SpecialCharTok{+}
\NormalTok{                         WorkLifeBalance, }
                       \AttributeTok{data =}\NormalTok{ train.data)}
\NormalTok{model\_nb}
\end{Highlighting}
\end{Shaded}

\newpage

\hypertarget{evaluation}{%
\section{7 Evaluation}\label{evaluation}}

\hypertarget{regression-models}{%
\subsection{7.1 Regression Models}\label{regression-models}}

We want to compare the initial regression model with the final model.
So, we evaluate the regression models computing the Mean Squared Error
(MSE) on the test set. Then we plot the residuals of the final model.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{initial\_predictions }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(model\_slr, }\AttributeTok{newdata =}\NormalTok{ test.data)}
\NormalTok{final\_predictions }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(final\_model, }\AttributeTok{newdata =}\NormalTok{ test.data)}
\NormalTok{initial\_mse }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{((test.data}\SpecialCharTok{$}\NormalTok{YearsAtCompany }\SpecialCharTok{{-}}\NormalTok{ initial\_predictions)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{final\_mse }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{((test.data}\SpecialCharTok{$}\NormalTok{YearsAtCompany }\SpecialCharTok{{-}}\NormalTok{ final\_predictions)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "MSE of the initial model on test set: 16.2086966065198"
\end{verbatim}

\begin{verbatim}
## [1] "MSE of the final model on test set: 9.3755059331471"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{residuals }\OtherTok{\textless{}{-}}\NormalTok{ test.data}\SpecialCharTok{$}\NormalTok{YearsAtCompany }\SpecialCharTok{{-}}\NormalTok{ final\_predictions}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(residuals, }\AttributeTok{pch =} \DecValTok{20}\NormalTok{, }\AttributeTok{main =} \StringTok{"Residuals of the final model"}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =} \DecValTok{0}\NormalTok{, }\AttributeTok{col =} \StringTok{"red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{Report_files/figure-latex/residuals-1} \end{center}

The Mean Squared Error of the final model is lower than the initial
model. The residuals of the final model are randomly distributed around
zero, which is a good sign.

\hypertarget{classification-models}{%
\subsection{7.2 Classification Models}\label{classification-models}}

We evaluate the classification models computing the performance metrics
used at lesson. We can compare the performance of the models and then we
plot the confusion matrix of the best model and the ROC curve.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{perf.measure }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(true.values, pred.values,  }\AttributeTok{lab.pos =} \DecValTok{1}\NormalTok{)\{}
\NormalTok{  conf.matrix }\OtherTok{\textless{}{-}} \FunctionTok{table}\NormalTok{(pred.values, true.values)}
\NormalTok{  n }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(conf.matrix)}
\NormalTok{  lab.pos }\OtherTok{\textless{}{-}} \FunctionTok{as.character}\NormalTok{(lab.pos)}
\NormalTok{  lab }\OtherTok{\textless{}{-}} \FunctionTok{rownames}\NormalTok{(conf.matrix)}
\NormalTok{  lab.neg }\OtherTok{\textless{}{-}}\NormalTok{ lab[lab }\SpecialCharTok{!=}\NormalTok{ lab.pos]}
\NormalTok{  TP }\OtherTok{\textless{}{-}}\NormalTok{ conf.matrix[lab.pos, lab.pos]}
\NormalTok{  TN }\OtherTok{\textless{}{-}}\NormalTok{ conf.matrix[lab.neg, lab.neg]}
\NormalTok{  FP }\OtherTok{\textless{}{-}}\NormalTok{ conf.matrix[lab.pos, lab.neg]}
\NormalTok{  FN }\OtherTok{\textless{}{-}}\NormalTok{ conf.matrix[lab.neg, lab.pos]}
\NormalTok{  P     }\OtherTok{\textless{}{-}}\NormalTok{ TP }\SpecialCharTok{+}\NormalTok{ FN}
\NormalTok{  N     }\OtherTok{\textless{}{-}}\NormalTok{ FP }\SpecialCharTok{+}\NormalTok{ TN}
\NormalTok{  P.ast }\OtherTok{\textless{}{-}}\NormalTok{ TP }\SpecialCharTok{+}\NormalTok{ FP}
\NormalTok{  OER }\OtherTok{\textless{}{-}}\NormalTok{ (FP}\SpecialCharTok{+}\NormalTok{FN)}\SpecialCharTok{/}\NormalTok{n}
\NormalTok{  PPV }\OtherTok{\textless{}{-}}\NormalTok{ TP}\SpecialCharTok{/}\NormalTok{P.ast}
\NormalTok{  TPR }\OtherTok{\textless{}{-}}\NormalTok{ TP}\SpecialCharTok{/}\NormalTok{P}
\NormalTok{  F1  }\OtherTok{\textless{}{-}} \DecValTok{2}\SpecialCharTok{*}\NormalTok{PPV}\SpecialCharTok{*}\NormalTok{TPR}\SpecialCharTok{/}\NormalTok{(PPV}\SpecialCharTok{+}\NormalTok{TPR)}
\NormalTok{  TNR }\OtherTok{\textless{}{-}}\NormalTok{ TN}\SpecialCharTok{/}\NormalTok{N}
\NormalTok{  FPR }\OtherTok{\textless{}{-}}\NormalTok{ FP}\SpecialCharTok{/}\NormalTok{N}
  \FunctionTok{return}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{overall.ER =}\NormalTok{ OER, }\AttributeTok{PPV=}\NormalTok{PPV, }\AttributeTok{TPR=}\NormalTok{TPR, }\AttributeTok{F1=}\NormalTok{F1, }\AttributeTok{TNR=}\NormalTok{TNR, }\AttributeTok{FPR=}\NormalTok{FPR))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

We compare the performance of the initial logistic regression model with
the final logistic regression model.

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Metric & Initial Model & Final Model \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Overall Error Rate & 0.15 & 0.14 \\
Positive Predictive Value (PPV) & 0.56 & 0.75 \\
True Positive Rate (TPR) & 0.13 & 0.16 \\
F1 Score & 0.22 & 0.26 \\
True Negative Rate (TNR) & 0.98 & 0.99 \\
False Positive Rate (FPR) & 0.02 & 0.01 \\
\end{longtable}

We plot the confusion matrix of the final logistic regression model.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{conf\_matrix }\OtherTok{\textless{}{-}} \FunctionTok{table}\NormalTok{(final\_predictions\_logit, test.data}\SpecialCharTok{$}\NormalTok{Attrition)}
\NormalTok{conf\_matrix}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                        
## final_predictions_logit  No Yes
##                     No  719 113
##                     Yes   7  21
\end{verbatim}

We plot the ROC curve of the final logistic regression model, compute
the AUC and find the best threshold.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{roc.out }\OtherTok{\textless{}{-}} \FunctionTok{roc}\NormalTok{(test.data}\SpecialCharTok{$}\NormalTok{Attrition, final\_prob\_logit, }\AttributeTok{levels=}\FunctionTok{c}\NormalTok{(}\StringTok{"No"}\NormalTok{, }\StringTok{"Yes"}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(roc.out,  }\AttributeTok{print.auc=}\ConstantTok{TRUE}\NormalTok{, }\AttributeTok{legacy.axes=}\ConstantTok{TRUE}\NormalTok{, }\AttributeTok{xlab=}\StringTok{"False Positive Rate"}\NormalTok{, }\AttributeTok{ylab=}\StringTok{"True Positive Rate"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{Report_files/figure-latex/roc_curve-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{auc}\NormalTok{(roc.out)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Area under the curve: 0.7571
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{coords}\NormalTok{(roc.out, }\StringTok{"best"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   threshold specificity sensitivity
## 1 0.1410504    0.661157   0.7686567
\end{verbatim}

The final logistic regression model has a better performance than the
initial model. The confusion matrix shows that the final model has a
higher number of true positives and true negatives. The ROC curve shows
that the final model has a higher AUC than the initial model.

\end{document}
