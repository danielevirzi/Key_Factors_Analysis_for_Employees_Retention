---
title: "Statistical Learning Project"
author: "Marlon Helbing, Nemanja Ilic, Daniele Virzì"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    latex_engine: xelatex
header-includes:
   - \usepackage{tikz}
   - \usetikzlibrary{shapes.geometric,arrows}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	fig.align = "center",
	fig.width = 10,
	fig.height = 15,
	message = FALSE,
	warning = FALSE
)
```

```{r directory, echo=FALSE}
# Clear current working environment
rm(list=ls())

# Get the directory of the current script
script_dir <- getwd()
```


# 1. Introduction

This project is a collaborative effort between three students, **Marlon Helbing**, **Nemanja Ilic**, **Daniele Virzì**. It is an academic project that will be graded based on the quality and depth of our analysis. The project aims to apply the concepts and techniques from the **Statistical Learning Course** to a real-world dataset. Our project is based on the **HR Analytics Case Study** and we will be using the **R** programming language to perform the analysis. As previously stated, the scope of this project is to assess the knowledge we have gained from the course. Because of this, in our project work, we were only allowed to utilize the models and techniques covered in the lectures; we were not permitted to use any `Tidyverse` R-packages, like `ggplot` or `ggplot2`.


## 1.1 Dataset

-   [**HR Analytics Case Study**](https://www.kaggle.com/datasets/vjchoudhary7/hr-analytics-case-study): This set of datasets, sourced from *Kaggle*, contains information about employees working in a company. These data are collected to understand why the employees are leaving the company and to predict the employees who are likely to leave the company. There are several datasets available for this case study but for our purposes we have chosen and merged just two of them, `general_data` and `employee_survey_data`. The final dataset contains 4410 observations and 27 variables. The variables are as follows:

    -   **`Age`**: Age of the employee.
    -   **`Attrition`**: Whether the employee has left the company or not.
    -   **`BusinessTravel`**: Frequency of travel for the employee.
    -   **`Department`**: Department of the employee.
    -   **`DistanceFromHome`**: Distance of the employee's residence from the company.
    -   **`Education`**: Education level of the employee.
    -   **`EducationField`**: Field of education of the employee.
    -   **`EmployeeCount`**: Employee count.
    -   **`EmployeeID`**: Employee ID.
    -   **`Gender`**: The gender of the employee.
    -   **`JobLevel`**: Job level of the employee.
    -   **`JobRole`**: Job role of the employee.
    -   **`MaritalStatus`**: Marital status of the employee.
    -   **`MonthlyIncome`**: Monthly income of the employee.
    -   **`NumCompaniesWorked`**: Number of companies the employee has worked for.
    -   **`Over18`**: Whether the employee is over 18 years old or not.
    -   **`PercentSalaryHike`**: Percentage increase in salary.
    -   **`StandardHours`**: Standard hours of work.
    -   **`StockOptionLevel`**: Stock option level of the employee.
    -   **`TotalWorkingYears`**: Total years the employee has worked.
    -   **`TrainingTimesLastYear`**: Number of times the employee was trained last year.
    -   **`YearsAtCompany`**: Number of years the employee has worked at the company.
    -   **`YearsSinceLastPromotion`**: Number of years since the last promotion.
    -   **`YearsWithCurrManager`**: Number of years the employee has worked with the current manager.
    -   **`EnvironmentSatisfaction`**: Environment satisfaction level of the employee.
    -   **`JobSatisfaction`**: Job satisfaction level of the employee.
    -   **`WorkLifeBalance`**: Work-life balance level of the employee.
    



## 1.2 Project goals

The main objectives of this project are:

-   **Regression Model**: To predict `YearsAtCompany` based on the available features, in order to understand the factors that influence the number of years an employee stays in the company. In this way, the company can take actions to retain employees for a longer period of time.


-  **Classification Model**: To predict `Attrition` based on the available features, in order to understand the factors that influence the attrition of employees in the company. In this way, the company can take actions to reduce the attrition rate.


## 1.3 Methodology

```{tikz, echo=FALSE, fig.align="center"}

\usetikzlibrary{shapes.geometric,arrows}

\begin{tikzpicture}[node distance=1.5cm, auto]

\tikzstyle{block}=[rectangle, draw, text width=10em, text centered, rounded      corners, minimum height=3em]
\tikzstyle{line}=[draw, -latex]  
\node [block] (1) {\textbf{Introduction}};  
\node [block, below of=1] (2)  {\textbf{Data Loading}};  
\node [block, below of=2] (3) {\textbf{Data Cleaning}};
\node [block, below of=3] (4) {\textbf{Data Preprocessing}};
\node [block, below of=4] (5) {\textbf{Exploratory Data Analysis}};
\node [block, below of=5] (6) {\textbf{Model Building}};
\node [block, below of=6] (7) {\textbf{Model Evaluation}};
\node [block, below of=7] (8) {\textbf{Conclusion}};


\path [line] (1)  -- (2);  
\path [line] (2)  -- (3);  
\path [line] (3) -- (4);
\path [line] (4) -- (5);
\path [line] (5) -- (6);
\path [line] (6) -- (7);
\path [line] (7) -- (8);

\end{tikzpicture}

```

# 2. Data Loading

We start by loading the necessary libraries and the data into the R environment. The libraries that we will be using in this project are:

```{r libraries, echo=TRUE}

library(MASS) # For step, glm, lda, qda
library(car) # For vif
library(corrplot) # For plotting correlation matrix
library(pROC) # For ROC curve

```

The data is loaded from the `general_data.csv` and `employee_survey_data.csv` files. We then merge the two datasets based on the `EmployeeID` variable.

```{r data_loading, echo=TRUE}
general_data <- read.csv("./data/general_data.csv")
employee_survey_data <- read.csv("./data/employee_survey_data.csv")
data <- merge(general_data, employee_survey_data, by = "EmployeeID")
```


# 3. Data Cleaning

## 3.1 Handling missing values

We check for missing values in the dataset and find that there are 111 misssing values.

```{r missing_values, echo=TRUE}

missing_values <- sum(is.na(data))
missing_values

data <- na.omit(data)
```

## 3.2 Handling duplicate rows

We check for duplicate rows in the dataset and find that there are no duplicate rows.

```{r duplicate_rows, echo=TRUE}
duplicates <- sum(duplicated(data))
duplicates
```

## 3.3 Removing unnecessary columns

We remove the `EmployeeID`, because it is a unique identifier and does not provide any useful information for the analysis. We also remove the `Over18`, `StandardHours`, and `EmployeeCount` columns because they have the same value for all employees and so the variance is zero.

```{r remove_columns, echo=TRUE}
data <- data[, !(names(data) %in% c("EmployeeID", "Over18", "StandardHours", "EmployeeCount"))]
```

# 4. Data Preprocessing

## 4.1 Encoding categorical variables

We encode the categorical variables as factors in order to use them in the regression and classification models.

```{r encoding, echo=TRUE}
data$Attrition <- factor(data$Attrition)
data$Gender <- factor(data$Gender)
data$BusinessTravel <- factor(data$BusinessTravel)
data$JobRole <- factor(data$JobRole)
data$Department <- factor(data$Department)
data$EducationField <- factor(data$EducationField)
data$MaritalStatus <- factor(data$MaritalStatus)
data$StockOptionLevel <- factor(data$StockOptionLevel)
data$Education <- factor(data$Education)
data$JobLevel <- factor(data$JobLevel)
data$EnvironmentSatisfaction <- factor(data$EnvironmentSatisfaction)
data$JobSatisfaction <- factor(data$JobSatisfaction)
data$WorkLifeBalance <- factor(data$WorkLifeBalance)
```

## 4.2 Log transformation

We perform log transformation on the `MonthlyIncome` variable to make it more normally distributed.

```{r log_transformation, echo=TRUE}
data$MonthlyIncome <- log(data$MonthlyIncome)
```

## 4.3 Check the structure of the dataset

We check the structure of the dataset to ensure that the data preprocessing steps have been applied correctly.

```{r structure, echo=TRUE}
str(data)
```

# 5. Exploratory Data Analysis

## 5.1 Categorical variables

We plot the distribution of the categorical variables in the dataset.

```{r categorical_variables1, echo=FALSE, fig.width=10, fig.height=10}
par(mfrow=c(2,3), 
    mar=c(4,2,2,2))


plot(data$EnvironmentSatisfaction,col=c(2:5), main="Environment Satisfaction", las=1)
plot(data$JobSatisfaction,col=c(2:5),main="Job Satisfaction", las=1)
plot(data$WorkLifeBalance,col=c(2:5),main="Work Life Balance", las=1)
plot(data$JobLevel,col=c(2:6),main="Job Level", las=1)
plot(data$Education,col=c(2:6),main="Education", las=1)
plot(data$StockOptionLevel,col=c(2:4),main="Stock Option Level", las=1)

```


```{r categorical_variables2, echo=FALSE, fig.width=11, fig.height=6}
par(mfrow=c(2,2), 
    mar=c(4,2,2,2))
plot(data$Gender,col=c(2:3),main="Gender", las=1)
plot(data$BusinessTravel,col=c(2:4),main="Business Travel", las=1)
plot(data$MaritalStatus,col=c(2:4),main="Marital Status", las=1)
plot(data$Department,col=c(2:4),main="Department", las=1)

```

```{r categorical_variables3, echo=FALSE, fig.width=10, fig.height=7}
par(mfrow=c(2,1), 
    mar=c(4,10,2,2))
plot(data$JobRole,col=c(2:10),main="Job Role", las=1, horiz=TRUE)
plot(data$EducationField,col=c(2:6),main="Education Field", las=1, horiz=TRUE)
```

\newpage

We notice that `JobSatisfaction` and `EnvironmentSatisfaction` are extremely similar. To check this we compute the chi squared statistic between these two. 

```{r chi_squared, echo=TRUE}

contingency_table <- table(data$EnvironmentSatisfaction, data$JobSatisfaction)
chi_squared <- chisq.test(contingency_table) 
chi_squared # 
data$EnvironmentSatisfaction <- NULL

```

## 5.2 Numerical variables

We plot the distribution of the numerical variables in the dataset.

```{r numerical_variables, echo=FALSE, fig.width=10, fig.height=8}
par(mfrow=c(2,4),  
    mar=c(2,2,2,2))

# Density plots for numerical variables
plot(density(data$Age), main = "Age", xlab = "Age", col = "skyblue", border = "white", lwd = 4)
plot(density(data$DistanceFromHome), main = "Distance from Home", xlab = "Distance from Home", col = "skyblue", border = "white", lwd = 4)
plot(density(data$TotalWorkingYears), main = "Total Working Years", xlab = "Total Working Years", col = "skyblue", border = "white", lwd = 4)
plot(density(data$PercentSalaryHike), main = "Percent Salary Hike", xlab = "Percent Salary Hike", col = "skyblue", border = "white", lwd = 4)

# Histograms for numerical variables
hist(data$TrainingTimesLastYear, main = "Training Times Last Year", xlab = "Training Times Last Year", col = "skyblue", border = "white")
hist(data$YearsSinceLastPromotion, main = "Years Since Last Promotion", xlab = "Years Since Last Promotion", col = "skyblue", border = "white")
hist(data$YearsWithCurrManager, main = "Years With Current Manager", xlab = "Years With Current Manager", col = "skyblue", border = "white")
hist(data$NumCompaniesWorked, main = "Number of Companies Worked", xlab = "Number of Companies Worked", col = "skyblue", border = "white")
```

## 5.3 Years At Company Analysis

We plot the distribution of the `YearsAtCompany` variable, our target variable for the regression model.

```{r years_at_company, echo=FALSE, fig.width=10, fig.height=3}
par(mfrow = c(1, 1), mar = c(4, 4, 2, 2) + 0.1, cex.axis = 0.8, cex.lab = 0.8)
hist(data$YearsAtCompany,
     main = "Distribution of Years at Company",
     xlab = "Years at Company",
     col = "skyblue",
     border = "white",
     breaks = 50)
```

Then we plot the boxplot of the `YearsAtCompany` variable against all the categorical variables in the dataset.

```{r years_at_company_boxplot, echo=FALSE, fig.width=10, fig.height=8}
par(mfrow = c(3, 4),
    mar = c(7, 4.5, 2, 2))

# Function to add rotated x-axis labels with vertical adjustment
add_rotated_labels <- function(labels, vertical_adjustment = 1) {
  text(x = seq_along(labels), y = par("usr")[3] - vertical_adjustment, srt = 45, adj = 1, labels = labels, xpd = TRUE, cex = 0.8)
}

boxplot(YearsAtCompany ~ Attrition, data = data, main = "Attrition", col = c(4, 6),  xlab = "")


boxplot(YearsAtCompany ~ BusinessTravel, data = data, main = "Business Travel", col = c(4, 6), xaxt = "n", xlab = "")
add_rotated_labels(levels(data$BusinessTravel))

boxplot(YearsAtCompany ~ Department, data = data, main = "Department", col = c(4, 6), xaxt = "n", xlab = "")
add_rotated_labels(levels(data$Department))

boxplot(YearsAtCompany ~ Education, data = data, main = "Education", col = c(4, 6),  xlab = "")


boxplot(YearsAtCompany ~ EducationField, data = data, main = "Education Field", col = c(4, 6), xaxt = "n", xlab = "")
add_rotated_labels(levels(data$EducationField))

boxplot(YearsAtCompany ~ Gender, data = data, main = "Gender", col = c(4, 6),  xlab = "")


boxplot(YearsAtCompany ~ JobLevel, data = data, main = "Job Level", col = c(4, 6),  xlab = "")


boxplot(YearsAtCompany ~ JobRole, data = data, main = "Job Role", col = c(4, 6), xaxt = "n", xlab = "") 
add_rotated_labels(levels(data$JobRole))

boxplot(YearsAtCompany ~ MaritalStatus, data = data, main = "Marital Status", col = c(4, 6),  xlab = "")


boxplot(YearsAtCompany ~ StockOptionLevel, data = data, main = "Stock Option Level", col = c(4, 6),  xlab = "")


boxplot(YearsAtCompany ~ JobSatisfaction, data = data, main = "Job Satisfaction", col = c(4, 6),  xlab = "")


boxplot(YearsAtCompany ~ WorkLifeBalance, data = data, main = "Work-Life Balance", col = c(4, 6),  xlab = "")

```

## 5.4 Attrition Analysis

We plot the distribution of the `Attrition` variable, our target variable for the classification model.

```{r attrition, echo=FALSE, fig.width=10, fig.height=5}
attrition_distribution <- table(data$Attrition)
par(mfrow = c(1, 1))
barplot(attrition_distribution,
        main = "Distribution of Attrition",
        xlab = "",
        ylab = "Frequency",
        col = "skyblue",
        border = "white",
        las = 0) 
```

Then we plot the boxplot of the `Attrition` variable against all the numerical variables in the dataset.

```{r attrition_boxplot, echo=FALSE, fig.width=10, fig.height=6}
par(mfrow=c(2,5),
    mar = c(4, 2, 2, 2))

boxplot(Age~Attrition,data=data,main="Age",col=c(4,6))
boxplot(DistanceFromHome~Attrition,data=data,main="DistanceFromHome",col=c(4,6))
boxplot(MonthlyIncome~Attrition,data=data,main="MonthlyIncome",col=c(4,6))
boxplot(NumCompaniesWorked~Attrition,data=data,main="NumCompaniesWorked",col=c(4,6))
boxplot(PercentSalaryHike~Attrition,data=data,main="PercentSalaryHike",col=c(4,6))
boxplot(TotalWorkingYears~Attrition,data=data,main="TotalWorkingYears",col=c(4,6))
boxplot(TrainingTimesLastYear~Attrition,data=data,main="TrainingTimesLastYear",col=c(4,6))
boxplot(YearsAtCompany~Attrition,data=data,main="YearsAtCompany",col=c(4,6))
boxplot(YearsSinceLastPromotion~Attrition,data=data,main="YearsSinceLastPromotion",col=c(4,6))
boxplot(YearsWithCurrManager~Attrition,data=data,main="YearsWithCurrManager",col=c(4,6))
```

## 5.5 Correlation Analysis

We calculate the correlation matrix of the numerical variables in the dataset.

```{r correlation_matrix, echo=FALSE, fig.width=10, fig.height=10}
par(mfrow = c(1, 1),
    mar = c(1, 1, 1, 1))
numeric_data <- data[, sapply(data, is.numeric)]
correlation_matrix <- cor(numeric_data)
corrplot(correlation_matrix, method = "color", type = "upper")
```

We notice that `YearsAtCompany` is highly correlated with `YearsWithCurrManager`. We will start from this variable to build the regression model. 

# 6. Model Building

We first split the dataset into a training set and a test set. We use 80% of the data for training and 20% for testing.

```{r split_data, echo=FALSE}
set.seed(123)

n <- dim(data)[1]

test <- sample(1:n, n*0.2) # indexes of data in the validation set
train <- setdiff(1:n, test) # indexes of data in training set

test.data <- data[test, ] # validation set
train.data <- data[train, ] # training set


length(test.data[1])
length(train.data[1])
```

## 6.1 Regression Model

We build a simple regression model to predict the `YearsAtCompany` variable. We use the `YearsWithCurrManager` variable as the predictor.

